#!/usr/bin/env python3
"""
Enhanced Thai OCR Pattern Detection - Targeted Error Identification

This script specifically identifies common Thai OCR errors that were missed
in the initial analysis, based on real-world examples from financial documents.
"""

import sqlite3
import re
from datetime import datetime
from collections import Counter, defaultdict
from typing import Dict, List, Set
from utils.thai_utils import is_thai_text, clean_thai_text


class EnhancedThaiPatternDetector:
    """Enhanced detection for specific Thai OCR errors"""

    def __init__(self, db_path: str = "data/prototype.db"):
        self.db_path = db_path
        self.conn = None
        self.cursor = None

        # Enhanced error patterns based on real examples
        self.specific_errors = {
            # Character corruption (à¸³ character issues)
            'à¸‡à¸šà¸›à¸µ': 'à¸‡à¸šà¸›à¸µ',  # Should be à¸‡à¸šà¸›à¸µ (proper spacing)
            'à¸‡à¸šà¸šà¸£à¸´à¸©à¸±à¸—': 'à¸‡à¸šà¸šà¸£à¸´à¸©à¸±à¸—',  # Company financial statements

            # Name/title corruption
            'à¸ˆà¸±à¸™à¸—à¸£à¹Œà¹€à¸à¹‡à¸': 'à¸ˆà¸±à¸™à¸—à¸£à¹Œà¹€à¸à¹‡à¸',  # Thai name corruption
            'à¹€à¸•à¸Šà¸°à¸à¹à¸²à¸˜à¸£': 'à¹€à¸•à¸Šà¸°à¸à¹à¸²à¸˜à¸£',  # Thai name corruption

            # Company type formatting
            'à¸ˆà¹à¸²à¸à¸±à¸”': 'à¸ˆà¸³à¸à¸±à¸”',  # Missing/ corrupted à¸³ character
            'à¸ˆà¹à¸²à¸à¸±à¸”': 'à¸ˆà¸³à¸à¸±à¸”',  # Character duplication/corruption

            # Common financial terms
            'à¸‡à¸šà¸à¹à¸²à¹„à¸£': 'à¸‡à¸šà¸à¸³à¹„à¸£',  # Income statement heading
            'à¸‡à¸šà¸ªà¸£à¸¸à¸›': 'à¸‡à¸šà¸ªà¸£à¸¸à¸›',  # Financial statements
            'à¸‚à¸²à¸”à¸—à¸¸à¸™': 'à¸‚à¸²à¸”à¸—à¸¸à¸™',  # Net loss

            # Character spacing issues
            'à¸ªà¸¸à¸—à¸˜à¸´': 'à¸ªà¸¸à¸—à¸˜à¸´',  # Thai spacing

            # Mixed Thai-English formatting
            'COMPANY.,LTD.': 'COMPANY LTD',  # English punctuation

            # Specific name corrections
            'à¸ˆà¹à¸²à¸™à¸§à¸™à¸›à¸µ': 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸µ',  # Number of years
        }

        # Pattern-based corrections using regex
        self.pattern_corrections = [
            # Fix à¸³ character corruption
            (r'à¸ˆà¹à¸²à¸à¸±', 'à¸ˆà¸³à¸à¸±à¸”'),
            (r'à¸„à¹à¸²à¸™à¸§à¸“', 'à¸„à¸³à¸™à¸§à¸“'),
            (r'à¸à¹à¸²à¹„à¸£', 'à¸à¸³à¹„à¸£'),
            (r'à¸‡à¸šà¸šà¸£à¸´à¸©à¸±à¸—', 'à¸‡à¸šà¸šà¸£à¸´à¸©à¸±à¸—'),
            (r'à¸‡à¸šà¸›à¸µ', 'à¸‡à¸šà¸›à¸µ'),
            (r'à¸ˆà¹à¸²à¸™à¸§à¸™à¸›à¸µ', 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸µ'),

            # Fix spacing around Thai words
            (r'à¸šà¸£à¸´à¸©à¸±à¸—\s+à¸ˆà¹à¸²à¸à¸±à¸”', 'à¸šà¸£à¸´à¸©à¸±à¸—à¸ˆà¸³à¸à¸±à¸”'),
            (r'à¸šà¸£à¸´à¸©à¸±à¸—\s+(\w)', r'à¸šà¸£à¸´à¸©à¸±à¸— \1'),

            # Fix name formatting
            (r'à¸ˆà¸±à¸™à¸—à¸£à¹Œà¹€à¸à¹‡à¸\s+à¹€à¸•à¸Šà¸°à¸à¹à¸²à¸˜à¸£', 'à¸ˆà¸±à¸™à¸—à¸£à¹Œà¹€à¸à¹‡à¸ à¹€à¸•à¸Šà¸°à¸à¹à¸²à¸˜à¸£'),

            # Financial statement formatting
            (r'à¸‡à¸šà¸à¹à¸²à¹„à¸£à¸‚à¸²à¸”à¸—à¸¸à¸™\s*\(([^)]+)\)', r'à¸‡à¸šà¸à¸³à¹„à¸£à¸‚à¸²à¸”à¸—à¸¸à¸™ (\1)'),
            (r'à¸‡à¸šà¸ªà¸£à¸¸à¸›\s*:\s*à¸‡à¸šà¸šà¸£à¸´à¸©à¸±à¸—', 'à¸‡à¸šà¸ªà¸£à¸¸à¸›: à¸‡à¸šà¸šà¸£à¸´à¸©à¸±à¸—'),

            # Thai period formatting
            (r'([0-9,]+)\.([0-9]{2})\s+à¸šà¸²à¸—', r'\1.\2 à¸šà¸²à¸—'),

            # Mixed punctuation
            (r'LTD\.', 'LTD'),
            (r'COMPANY,\s*LTD\.', 'COMPANY LTD'),
        ]

        # Common Thai business terms that should be recognized as correct
        self.valid_terms = {
            'à¸šà¸£à¸´à¸©à¸±à¸—', 'à¸ˆà¸³à¸à¸±à¸”', 'à¸¡à¸«à¸²à¸Šà¸™', 'à¸«à¹‰à¸²à¸‡à¸«à¸¸à¹‰à¸™à¸ªà¹ˆà¸§à¸™', 'à¸ªà¸²à¸¡à¸±à¸',
            'à¸‡à¸šà¸à¸²à¸£à¹€à¸‡à¸´à¸™', 'à¸‡à¸šà¸”à¸¸à¸¥', 'à¸‡à¸šà¸à¸³à¹„à¸£', 'à¸‡à¸šà¸ªà¸£à¸¸à¸›', 'à¸‡à¸šà¹à¸ªà¸”à¸‡',
            'à¸£à¸²à¸¢à¹„à¸”à¹‰', 'à¸£à¸²à¸¢à¸ˆà¹ˆà¸²à¸¢', 'à¸à¸³à¹„à¸£', 'à¸‚à¸²à¸”à¸—à¸¸à¸™', 'à¸—à¸¸à¸™', 'à¸ªà¸´à¸™à¸—à¸£à¸±à¸à¸¢à¹Œ',
            'à¸«à¸™à¸µà¹‰', 'à¸ªà¸¸à¸—à¸˜à¸´', 'à¸”à¸­à¸à¹€à¸šà¸µà¹‰à¸¢', 'à¸ à¸²à¸©à¸µ', 'à¸šà¸²à¸—',
            'à¸œà¸¹à¹‰à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸šà¸±à¸à¸Šà¸µ', 'à¸à¸£à¸£à¸¡à¸à¸²à¸£', 'à¸›à¸£à¸°à¸˜à¸²à¸™', 'à¸ˆà¸”à¸—à¸°à¹€à¸šà¸µà¸¢à¸™',
            'à¸ªà¸³à¸™à¸±à¸à¸‡à¸²à¸™à¹ƒà¸«à¸à¹ˆ', 'à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ', 'à¹‚à¸—à¸£à¸¨à¸±à¸à¸—à¹Œ', 'à¸­à¸µà¹€à¸¡à¸¥', 'à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œ',
        }

    def connect(self) -> bool:
        """Connect to database"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row
            self.cursor = self.conn.cursor()
            return True
        except Exception as e:
            print(f"Error connecting to database: {e}")
            return False

    def extract_sample_texts(self, limit: int = 100) -> List[str]:
        """Extract sample texts for manual verification"""
        if not self.cursor:
            return []

        texts = []

        try:
            # Get sample table content
            self.cursor.execute("""
                SELECT value FROM table_cells
                WHERE value IS NOT NULL AND LENGTH(value) > 10
                ORDER BY RANDOM()
                LIMIT ?
            """, (limit,))

            for row in self.cursor.fetchall():
                if is_thai_text(row[0]):
                    texts.append(row[0])

            # Get sample document content
            self.cursor.execute("""
                SELECT file_path, document_type FROM documents
                WHERE file_path LIKE '%.pdf'
                ORDER BY RANDOM()
                LIMIT 20
            """)

            for row in self.cursor.fetchall():
                texts.append(f"Document: {row[0]} ({row[1]})")

        except Exception as e:
            print(f"Error extracting samples: {e}")

        return texts

    def find_specific_errors(self, texts: List[str]) -> Dict:
        """Find specific Thai OCR errors based on enhanced patterns"""
        error_analysis = {
            'total_texts': len(texts),
            'errors_found': defaultdict(int),
            'error_examples': defaultdict(list),
            'corrections_needed': []
        }

        for text in texts:
            cleaned_text = clean_thai_text(text)

            # Check each specific error pattern
            for error, correction in self.specific_errors.items():
                if error in cleaned_text:
                    error_analysis['errors_found'][error] += 1

                    # Store example (first occurrence only)
                    if len(error_analysis['error_examples'][error]) < 3:
                        error_analysis['error_examples'][error].append(text)

                    # Add to corrections list if not already added
                    existing = [c['error_pattern'] for c in error_analysis['corrections_needed']]
                    if error not in existing:
                        error_analysis['corrections_needed'].append({
                            'error_pattern': error,
                            'correction': correction,
                            'frequency': error_analysis['errors_found'][error],
                            'type': 'specific_corruption',
                            'confidence': 0.95,
                            'description': f"Specific OCR error: {error} â†’ {correction}",
                            'example': f"Found: {error}, Correct: {correction}"
                        })

            # Apply pattern-based corrections
            for pattern, replacement in self.pattern_corrections:
                if re.search(pattern, cleaned_text):
                    matches = re.findall(pattern, cleaned_text)
                    if matches:
                        error_key = f"Pattern: {pattern[:20]}..."
                        error_analysis['errors_found'][error_key] += len(matches)

                        if len(error_analysis['error_examples'][error_key]) < 3:
                            error_analysis['error_examples'][error_key].append(text)

                        # Add to corrections if not already present
                        existing = [c['error_pattern'] for c in error_analysis['corrections_needed']]
                        if pattern not in existing:
                            error_analysis['corrections_needed'].append({
                                'error_pattern': pattern,
                                'correction': replacement,
                                'frequency': len(matches),
                                'type': 'pattern_based',
                                'confidence': 0.85,
                                'description': f"Regex pattern: {pattern} â†’ {replacement}",
                                'example': f"Example: {matches[0]} â†’ {replacement}"
                            })

        return error_analysis

    def analyze_current_corrections(self) -> Dict:
        """Analyze current corrections to see what errors they address"""
        if not self.cursor:
            return {}

        try:
            self.cursor.execute("""
                SELECT error_pattern, correction, frequency, type, description
                FROM thai_ocr_corrections
                WHERE is_active = 1
                ORDER BY frequency DESC
            """)

            current_corrections = {}
            for row in self.cursor.fetchall():
                current_corrections[row['error_pattern']] = dict(row)

            return current_corrections

        except Exception as e:
            print(f"Error analyzing current corrections: {e}")
            return {}

    def generate_enhanced_corrections(self, new_errors: List[Dict],
                                       current_corrections: Dict) -> List[Dict]:
        """Generate enhanced corrections combining new findings with existing"""
        enhanced_corrections = []

        # Add high-priority new corrections
        for error in new_errors:
            # Skip if already exists with same correction
            existing_key = f"{error['error_pattern']}->{error['correction']}"
            if existing_key in [f"{c['error_pattern']}->{c['correction']}" for c in enhanced_corrections]:
                continue

            # Prioritize by frequency and confidence
            if error['frequency'] >= 5 or error['confidence'] >= 0.90:
                enhanced_corrections.append(error)

        # Keep existing corrections that are still valuable
        for pattern, correction in current_corrections.items():
            if correction['frequency'] >= 10:  # Keep well-established corrections
                enhanced_corrections.append({
                    'error_pattern': pattern,
                    'correction': correction['correction'],
                    'frequency': correction['frequency'],
                    'type': correction['type'],
                    'confidence': 0.85,
                    'description': correction['description'],
                    'example': f"Existing: {pattern} â†’ {correction['correction']}",
                    'priority': 'maintained'
                })

        # Sort by frequency and confidence
        enhanced_corrections.sort(
            key=lambda x: (x['frequency'], x['confidence']),
            reverse=True
        )

        return enhanced_corrections

    def create_error_examples_report(self, error_analysis: Dict) -> str:
        """Create detailed error examples report"""
        report_lines = []
        report_lines.append("# Thai OCR Error Examples Report")
        report_lines.append("=" * 50)
        report_lines.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"Total texts analyzed: {error_analysis['total_texts']}")
        report_lines.append(f"Error types found: {len(error_analysis['errors_found'])}")
        report_lines.append("")

        report_lines.append("## Error Examples by Type")
        report_lines.append("")

        for error_type, examples in error_analysis['error_examples'].items():
            count = error_analysis['errors_found'][error_type]
            report_lines.append(f"### {error_type} (Found {count} times)")
            report_lines.append("")

            for i, example in enumerate(examples[:2], 1):  # Show up to 2 examples
                # Clean up the example for readability
                if len(example) > 200:
                    example = example[:200] + "..."

                report_lines.append(f"Example {i}:")
                report_lines.append(f"```")
                report_lines.append(example)
                report_lines.append("```")
                report_lines.append("")

        return '\n'.join(report_lines)

    def run_enhanced_analysis(self):
        """Run the enhanced pattern detection"""
        print("ğŸ” Running Enhanced Thai OCR Pattern Detection...")
        print("=" * 60)

        if not self.connect():
            return

        # Get sample texts
        texts = self.extract_sample_texts(limit=200)
        print(f"ğŸ“ Analyzing {len(texts)} sample texts...")

        # Find specific errors
        error_analysis = self.find_specific_errors(texts)
        print(f"â“ Found {len(error_analysis['errors_found'])} error types")
        print(f"ğŸ’¡ Generated {len(error_analysis['corrections_needed'])} correction candidates")

        # Analyze current corrections
        current_corrections = self.analyze_current_corrections()
        print(f"ğŸ“š Current corrections in database: {len(current_corrections)}")

        # Generate enhanced corrections
        enhanced_corrections = self.generate_enhanced_corrections(
            error_analysis['corrections_needed'],
            current_corrections
        )
        print(f"ğŸ¯ Enhanced corrections generated: {len(enhanced_corrections)}")

        # Create examples report
        examples_report = self.create_error_examples_report(error_analysis)
        with open('thai_ocr_error_examples.md', 'w', encoding='utf-8') as f:
            f.write(examples_report)
        print("ğŸ’¾ Error examples saved to thai_ocr_error_examples.md")

        # Display top findings
        print("\nğŸ¯ Top New Error Patterns Found:")
        for i, error in enumerate(error_analysis['corrections_needed'][:10], 1):
            print(f"   {i}. {error['error_pattern']} â†’ {error['correction']} "
                  f"(freq: {error['frequency']}, conf: {error['confidence']:.2f})")

        print(f"\nğŸ“Š Error Type Summary:")
        for error_type, count in sorted(error_analysis['errors_found'].items(),
                                     key=lambda x: x[1], reverse=True):
            print(f"   {error_type}: {count} occurrences")

        # Close connection
        self.conn.close()

        return error_analysis, enhanced_corrections


def main():
    """Main execution function"""
    detector = EnhancedThaiPatternDetector()
    error_analysis, enhanced_corrections = detector.run_enhanced_analysis()

    print("\nâœ… Enhanced pattern detection complete!")


if __name__ == "__main__":
    main()