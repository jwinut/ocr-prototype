# Thai Financial Document OCR Prototype - Implementation Workflow

## Project Overview

**Goal**: Create a GUI-based prototype to process Thai financial PDFs from Y67 folder with real-time feedback, supporting both existing files and new uploads.

**Key Requirements**:
- GUI interface for ease of use
- Real-time processing feedback (progress bars, status updates)
- Volatile/dynamic - process new PDFs on demand
- Structured data output for backend/AI agent use
- Relational database storage

**Team**: 3 AI developers working in parallel

---

## ðŸ“Š Implementation Progress Tracker

> **Last Updated**: 2024-11-25 22:45

### Overall Status: ðŸŸ¢ READY FOR TESTING

| Phase | Status | Progress |
|-------|--------|----------|
| Planning | âœ… Complete | 100% |
| DEV-1 (ALPHA) Backend | âœ… Complete | 100% |
| DEV-2 (BETA) Processing | âœ… Complete | 100% |
| DEV-3 (GAMMA) GUI | âœ… Complete | 100% |
| Integration | âœ… Complete | 100% |
| Testing | â³ Pending | 0% |

### ðŸ§ª Quick Verification Results
```
Scanner Test: âœ… PASSED
- Found 91 documents across 10 companies
- Y67 folder structure correctly parsed
- Thai company names extracted successfully

Dependencies Required:
pip install sqlalchemy pandas streamlit docling easyocr
```

### DEV-1 (ALPHA) Backend/Database âœ…
- [x] `models/schema.py` - SQLAlchemy ORM (Company, FiscalYear, Document, ExtractedTable, TableCell)
- [x] `app/config.py` - Shared configuration
- [x] `app/database.py` - DatabaseManager with full CRUD
- [x] `utils/validators.py` - Data validation utilities
- [x] `scripts/init_database.py` - Database initialization

### DEV-2 (BETA) Processing Engine âœ…
- [x] `processing/scanner.py` - File discovery & metadata extraction
- [x] `processing/ocr.py` - Docling wrapper with Thai OCR (EasyOCR)
- [x] `processing/parser.py` - Data normalization, Thai number handling
- [x] `processing/batch.py` - Batch processing with progress callbacks
- [x] `utils/thai_utils.py` - Thai text utilities

### DEV-3 (GAMMA) GUI/Frontend âœ…
- [x] `app/main.py` - Dashboard with stats and quick actions
- [x] `app/pages/1_ðŸ“_Browse.py` - File browser with filters
- [x] `app/pages/2_âš™ï¸_Process.py` - Processing view with progress
- [x] `app/pages/3_ðŸ“Š_Results.py` - Results viewer with export
- [x] `app/pages/4_â¬†ï¸_Upload.py` - Upload page with validation
- [x] `.streamlit/config.toml` - Streamlit configuration

### Integration Status âœ…
- [x] Database layer created and tested
- [x] Processing engine created with interfaces
- [x] GUI created with mock data
- [x] Wire GUI to Database (DatabaseManager)
- [x] Wire GUI to Processing (DocumentProcessor, Scanner)
- [x] Lazy imports for graceful dependency handling
- [ ] End-to-end testing with real OCR (requires dependencies)

### Files Created (24 total)
```
claude/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          [DEV-1]
â”‚   â”œâ”€â”€ database.py         [DEV-1]
â”‚   â”œâ”€â”€ main.py             [DEV-3]
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_ðŸ“_Browse.py  [DEV-3]
â”‚       â”œâ”€â”€ 2_âš™ï¸_Process.py [DEV-3]
â”‚       â”œâ”€â”€ 3_ðŸ“Š_Results.py [DEV-3]
â”‚       â””â”€â”€ 4_â¬†ï¸_Upload.py  [DEV-3]
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py         [DEV-1]
â”‚   â””â”€â”€ schema.py           [DEV-1]
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ __init__.py         [DEV-2]
â”‚   â”œâ”€â”€ scanner.py          [DEV-2]
â”‚   â”œâ”€â”€ ocr.py              [DEV-2]
â”‚   â”œâ”€â”€ parser.py           [DEV-2]
â”‚   â””â”€â”€ batch.py            [DEV-2]
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validators.py       [DEV-1]
â”‚   â””â”€â”€ thai_utils.py       [DEV-2]
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_basic.py
â”‚   â”œâ”€â”€ test_processing.py
â”‚   â””â”€â”€ test_minimal.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_database.py
â”‚   â””â”€â”€ verify_structure.py
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml         [DEV-3]
â””â”€â”€ requirements.txt
```

---

## Technology Stack

### Core Processing
| Component | Technology | Rationale |
|-----------|------------|-----------|
| OCR Engine | **Docling** | Document structure + Thai OCR + Table extraction |
| Language | Python 3.11+ | Docling compatibility |
| Database | **SQLite** (dev) â†’ PostgreSQL (prod) | Simple start, easy migration |

### GUI Framework: **Streamlit**

Selected over Gradio because:
- Better for data dashboards and file processing workflows
- Native progress bars and status updates
- Stronger file upload handling
- More customizable UI
- Better data visualization (tables, charts)

```
Streamlit Advantages for This Project:
â”œâ”€â”€ st.file_uploader() - Multiple PDF upload
â”œâ”€â”€ st.progress() - Real-time OCR progress
â”œâ”€â”€ st.dataframe() - Display extracted tables
â”œâ”€â”€ st.status() - Processing status containers
â”œâ”€â”€ Session state - Maintain processing state
â””â”€â”€ Easy deployment - Single command
```

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STREAMLIT GUI                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ File Browser â”‚  â”‚ Upload Zone  â”‚  â”‚ Processing Dashboard â”‚  â”‚
â”‚  â”‚ (Y67 folder) â”‚  â”‚ (New PDFs)   â”‚  â”‚ (Status & Progress)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Results Viewer                           â”‚ â”‚
â”‚  â”‚  â€¢ Extracted Text  â€¢ Tables (DataFrame)  â€¢ JSON Preview    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSING ENGINE                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Document Scannerâ”‚ -> â”‚ Docling OCR     â”‚ -> â”‚ Data Parser â”‚ â”‚
â”‚  â”‚ (File discovery)â”‚    â”‚ (Thai+English)  â”‚    â”‚ (Normalize) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA STORAGE (SQLite)                         â”‚
â”‚  companies â”€> fiscal_years â”€> documents â”€> extracted_tables     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Team Structure & Parallel Workstreams

### 3 AI Developer Assignments

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PARALLEL DEVELOPMENT TRACKS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     DEV-1 (ALPHA)   â”‚  â”‚     DEV-2 (BETA)    â”‚  â”‚    DEV-3 (GAMMA)    â”‚ â”‚
â”‚  â”‚   Backend/Database  â”‚  â”‚   Processing Engine â”‚  â”‚    GUI/Frontend     â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ Database schema   â”‚  â”‚ â€¢ Docling OCR setup â”‚  â”‚ â€¢ Streamlit app     â”‚ â”‚
â”‚  â”‚ â€¢ SQLAlchemy models â”‚  â”‚ â€¢ Thai OCR config   â”‚  â”‚ â€¢ Dashboard page    â”‚ â”‚
â”‚  â”‚ â€¢ CRUD operations   â”‚  â”‚ â€¢ Batch processing  â”‚  â”‚ â€¢ File browser      â”‚ â”‚
â”‚  â”‚ â€¢ Data validation   â”‚  â”‚ â€¢ Table extraction  â”‚  â”‚ â€¢ Processing view   â”‚ â”‚
â”‚  â”‚ â€¢ Export functions  â”‚  â”‚ â€¢ Error handling    â”‚  â”‚ â€¢ Results viewer    â”‚ â”‚
â”‚  â”‚ â€¢ Query utilities   â”‚  â”‚ â€¢ Progress tracking â”‚  â”‚ â€¢ Upload component  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                        â”‚                        â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                    â–¼                                        â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                        â”‚   INTEGRATION POINT â”‚                              â”‚
â”‚                        â”‚   (Day 4-5 Sync)    â”‚                              â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Developer Assignments

### DEV-1 (ALPHA): Backend & Database Specialist

**Responsibility**: Data layer, persistence, and API contracts

#### Files to Create:
```
claude/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schema.py               # SQLAlchemy ORM models
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ database.py             # Database connection & operations
â”‚   â””â”€â”€ config.py               # Shared configuration
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ validators.py           # Data validation utilities
â””â”€â”€ data/
    â””â”€â”€ prototype.db            # SQLite database
```

#### Task Breakdown:

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| 1 | Design & implement database schema | `models/schema.py` with all tables |
| 1 | Create SQLAlchemy models | Company, FiscalYear, Document, ExtractedTable, TableCell models |
| 2 | Implement CRUD operations | `app/database.py` with full CRUD |
| 2 | Create data validation layer | Input validation, type checking |
| 3 | Build export functions | CSV, JSON, SQL dump exports |
| 3 | Create query utilities | Search, filter, aggregate functions |
| 4 | Write unit tests | `tests/test_database.py` |
| 4 | API contract documentation | Interface specs for DEV-2/DEV-3 |

#### Key Interfaces to Expose:
```python
# Database interface for other devs
class DatabaseManager:
    def get_or_create_company(company_code: str, name: str) -> Company
    def create_document(fiscal_year_id: int, doc_type: str, path: str) -> Document
    def store_extracted_table(document_id: int, table_data: dict) -> ExtractedTable
    def get_documents_by_status(status: str) -> List[Document]
    def get_company_summary() -> dict  # Stats for dashboard
    def search_documents(query: str) -> List[Document]
    def export_to_csv(document_id: int) -> str
    def export_to_json(document_id: int) -> dict
```

---

### DEV-2 (BETA): Processing Engine Specialist

**Responsibility**: OCR pipeline, document processing, data extraction

#### Files to Create:
```
claude/
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scanner.py              # File discovery & metadata
â”‚   â”œâ”€â”€ ocr.py                  # Docling wrapper
â”‚   â”œâ”€â”€ parser.py               # Data normalization
â”‚   â””â”€â”€ batch.py                # Batch processing with progress
â””â”€â”€ utils/
    â””â”€â”€ thai_utils.py           # Thai text utilities
```

#### Task Breakdown:

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| 1 | Set up Docling with Thai OCR | Working Thai OCR config |
| 1 | Create document scanner | `processing/scanner.py` |
| 2 | Build OCR wrapper class | `processing/ocr.py` with progress callbacks |
| 2 | Implement table extraction | Table â†’ DataFrame conversion |
| 3 | Create data parser/normalizer | Thai number handling, text cleanup |
| 3 | Build batch processor | `processing/batch.py` with queue |
| 4 | Error handling & recovery | Graceful failure, retry logic |
| 4 | Performance optimization | Caching, parallel processing |

#### Key Interfaces to Expose:
```python
# Processing interface for DEV-3 GUI
class DocumentProcessor:
    def scan_directory(path: str) -> List[DocumentInfo]
    def process_single(path: str, progress_cb: Callable) -> ProcessedDocument
    def process_batch(paths: List[str], progress_cb: Callable) -> Generator[ProcessedDocument]
    def get_processing_status() -> dict  # Current queue status

@dataclass
class ProcessedDocument:
    status: str  # success, failed, partial
    tables: List[pd.DataFrame]
    text_content: str
    markdown: str
    json_data: dict
    errors: List[str]
    processing_time: float
```

---

### DEV-3 (GAMMA): GUI/Frontend Specialist

**Responsibility**: Streamlit application, user interface, user experience

#### Files to Create:
```
claude/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Streamlit entry point & dashboard
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_ðŸ“_Browse.py      # File browser
â”‚       â”œâ”€â”€ 2_âš™ï¸_Process.py     # Processing view
â”‚       â”œâ”€â”€ 3_ðŸ“Š_Results.py     # Results viewer
â”‚       â””â”€â”€ 4_â¬†ï¸_Upload.py      # Upload new files
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml             # Streamlit settings
â””â”€â”€ assets/
    â””â”€â”€ styles.css              # Custom styling (optional)
```

#### Task Breakdown:

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| 1 | Streamlit project setup | Base app structure, config |
| 1 | Dashboard page (main.py) | Stats, quick actions, activity feed |
| 2 | File browser page | Company/year/type filters, file list |
| 2 | Processing view page | Progress bars, logs, status |
| 3 | Results viewer page | Tables, text, JSON tabs, exports |
| 3 | Upload page | Drag-drop upload, validation |
| 4 | Session state management | Persist state across pages |
| 4 | Error handling & feedback | User-friendly error messages |

#### Key UI Components:
```python
# Components DEV-3 will build
def render_dashboard():
    """Main dashboard with stats and quick actions"""

def render_file_browser(documents: List[DocumentInfo]):
    """Filterable file list with selection"""

def render_processing_view(processor: DocumentProcessor):
    """Real-time progress with logs"""

def render_results_viewer(document: ProcessedDocument):
    """Multi-tab results display"""

def render_upload_zone():
    """Drag-drop upload with validation"""
```

---

## Parallel Timeline (5 Days)

```
Day 1: Foundation (All Parallel)
â”œâ”€â”€ DEV-1: Database schema + SQLAlchemy models
â”œâ”€â”€ DEV-2: Docling setup + Thai OCR verification
â””â”€â”€ DEV-3: Streamlit setup + Dashboard skeleton

Day 2: Core Implementation (All Parallel)
â”œâ”€â”€ DEV-1: CRUD operations + validation
â”œâ”€â”€ DEV-2: OCR wrapper + scanner
â””â”€â”€ DEV-3: File browser + Processing view

Day 3: Feature Complete (All Parallel)
â”œâ”€â”€ DEV-1: Export functions + queries
â”œâ”€â”€ DEV-2: Batch processing + parser
â””â”€â”€ DEV-3: Results viewer + Upload page

Day 4: Integration (Sync Point)
â”œâ”€â”€ MORNING: All devs sync interfaces
â”œâ”€â”€ AFTERNOON: Wire up components
â”‚   â”œâ”€â”€ DEV-3 integrates DEV-1 database calls
â”‚   â”œâ”€â”€ DEV-3 integrates DEV-2 processing calls
â”‚   â””â”€â”€ DEV-1 + DEV-2 verify data flow
â””â”€â”€ EVENING: Integration testing

Day 5: Polish & Test
â”œâ”€â”€ ALL: Bug fixes from integration
â”œâ”€â”€ ALL: End-to-end testing with real PDFs
â”œâ”€â”€ DEV-1: Data validation edge cases
â”œâ”€â”€ DEV-2: Processing performance tuning
â””â”€â”€ DEV-3: UI polish, error handling
```

---

## Integration Contracts

### Contract 1: DEV-1 â†” DEV-2 (Database â†” Processing)

```python
# DEV-2 calls DEV-1's database functions to store results

# After processing a document:
from app.database import DatabaseManager

db = DatabaseManager()

# Store processed document
document = db.create_document(
    fiscal_year_id=fiscal_year.id,
    document_type="balance_sheet",
    file_path="/path/to/file.pdf",
    status="completed"
)

# Store extracted tables
for idx, df in enumerate(processed.tables):
    db.store_extracted_table(
        document_id=document.id,
        table_index=idx,
        headers=list(df.columns),
        data=df.to_dict('records'),
        markdown=df.to_markdown()
    )
```

### Contract 2: DEV-2 â†” DEV-3 (Processing â†” GUI)

```python
# DEV-3 calls DEV-2's processing functions from Streamlit

from processing.ocr import DocumentProcessor
from processing.scanner import scan_directory

# In Streamlit page:
processor = DocumentProcessor()

# Scan for files
documents = scan_directory("../Y67")

# Process with progress callback
def update_progress(percent, message):
    progress_bar.progress(percent)
    status_text.text(message)

result = processor.process_single(
    path=selected_file,
    progress_cb=update_progress
)

# Display results
st.dataframe(result.tables[0])
st.markdown(result.markdown)
```

### Contract 3: DEV-1 â†” DEV-3 (Database â†” GUI)

```python
# DEV-3 calls DEV-1's database functions for display

from app.database import DatabaseManager

db = DatabaseManager()

# Dashboard stats
stats = db.get_company_summary()
st.metric("Total Companies", stats['company_count'])
st.metric("Processed Files", stats['processed_count'])

# File browser data
documents = db.get_documents_by_status("pending")
st.dataframe(documents)

# Export functionality
csv_data = db.export_to_csv(document_id)
st.download_button("Download CSV", csv_data)
```

---

## Shared Configuration (All Devs)

```python
# app/config.py - Created by DEV-1, used by all

from pathlib import Path
from dataclasses import dataclass

@dataclass
class Config:
    # Paths
    PROJECT_ROOT: Path = Path(__file__).parent.parent
    Y67_BASE_PATH: Path = PROJECT_ROOT.parent / "Y67"
    DATABASE_PATH: Path = PROJECT_ROOT / "data" / "prototype.db"
    EXPORTS_PATH: Path = PROJECT_ROOT / "data" / "exports"

    # OCR Settings (DEV-2 uses)
    OCR_LANGUAGES: list = ("th", "en")
    OCR_CONFIDENCE_THRESHOLD: float = 0.5
    TABLE_MODE: str = "ACCURATE"  # ACCURATE or FAST

    # Processing Settings
    MAX_BATCH_SIZE: int = 10
    PROCESSING_TIMEOUT: int = 300  # seconds per file

    # GUI Settings (DEV-3 uses)
    PAGE_SIZE: int = 20
    MAX_UPLOAD_SIZE_MB: int = 200

config = Config()
```

---

## Communication Protocol

### Daily Standups
```
Format: Async message in shared channel
Time: Start of each day
Content:
- Yesterday: What was completed
- Today: What will be worked on
- Blockers: Any issues needing help
- Interface changes: Any API/contract changes
```

### Integration Checkpoints
```
Day 2 EOD: Interface Review
- All devs share their interface definitions
- Identify any mismatches
- Agree on data structures

Day 4 Start: Integration Sync
- 30-min sync meeting
- Merge branches
- Resolve conflicts
- Test basic data flow
```

### Shared Resources
```
claude/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ api_contracts.md        # Interface definitions
â”‚   â”œâ”€â”€ data_structures.md      # Shared types
â”‚   â””â”€â”€ integration_notes.md    # Integration decisions
â””â”€â”€ tests/
    â””â”€â”€ integration/            # Cross-component tests
```

---

## File Structure (Final)

```
~/ocr-prototype/claude/
â”œâ”€â”€ app/                        # DEV-3 primary, DEV-1 config
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # [DEV-3] Streamlit entry
â”‚   â”œâ”€â”€ config.py               # [DEV-1] Shared config
â”‚   â”œâ”€â”€ database.py             # [DEV-1] Database operations
â”‚   â””â”€â”€ pages/                  # [DEV-3] Streamlit pages
â”‚       â”œâ”€â”€ 1_ðŸ“_Browse.py
â”‚       â”œâ”€â”€ 2_âš™ï¸_Process.py
â”‚       â”œâ”€â”€ 3_ðŸ“Š_Results.py
â”‚       â””â”€â”€ 4_â¬†ï¸_Upload.py
â”œâ”€â”€ processing/                 # [DEV-2] Primary
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scanner.py
â”‚   â”œâ”€â”€ ocr.py
â”‚   â”œâ”€â”€ parser.py
â”‚   â””â”€â”€ batch.py
â”œâ”€â”€ models/                     # [DEV-1] Primary
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schema.py
â”œâ”€â”€ utils/                      # Shared
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validators.py           # [DEV-1]
â”‚   â””â”€â”€ thai_utils.py           # [DEV-2]
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_database.py        # [DEV-1]
â”‚   â”œâ”€â”€ test_processing.py      # [DEV-2]
â”‚   â”œâ”€â”€ test_gui.py             # [DEV-3]
â”‚   â””â”€â”€ integration/            # [ALL]
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ prototype.db
â”‚   â””â”€â”€ exports/
â”œâ”€â”€ .streamlit/                 # [DEV-3]
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ requirements.txt            # Shared
â”œâ”€â”€ README.md                   # Shared
â””â”€â”€ docs/
    â”œâ”€â”€ docling_thai_ocr_research.md
    â”œâ”€â”€ prototype_workflow.md
    â”œâ”€â”€ api_contracts.md
    â””â”€â”€ integration_notes.md
```

---

## Dependencies

```txt
# requirements.txt
# Core
docling[vlm]>=2.0.0
streamlit>=1.30.0

# Database
sqlalchemy>=2.0.0
alembic>=1.13.0

# Data Processing
pandas>=2.0.0
numpy>=1.24.0

# Utilities
python-dotenv>=1.0.0
tqdm>=4.66.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0

# Optional: GPU acceleration
# torch>=2.0.0  # Uncomment if using CUDA
```

---

## Quick Start Commands

```bash
# 1. Create virtual environment
cd ~/ocr-prototype/claude
python -m venv venv
source venv/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Initialize database (after DEV-1 completes schema)
python -c "from app.database import init_db; init_db()"

# 4. Run the app (after DEV-3 completes main.py)
streamlit run app/main.py

# 5. Access in browser
# http://localhost:8501
```

---

## Success Criteria

| Metric | Target |
|--------|--------|
| Thai OCR Accuracy | >90% on printed text |
| Table Extraction | >95% structure preserved |
| Processing Speed | <30s per PDF (no GPU) |
| GUI Responsiveness | <2s for UI updates |
| New File Support | Immediate processing capability |
| Parallel Dev Efficiency | 60% time reduction vs sequential |

---

## Risk Mitigation

| Risk | Mitigation | Owner |
|------|------------|-------|
| Poor Thai OCR quality | Test early, try Tesseract as fallback | DEV-2 |
| Slow processing | Add GPU support, implement caching | DEV-2 |
| Memory issues with large PDFs | Process page-by-page, limit batch size | DEV-2 |
| Complex table structures | Use ACCURATE mode, add manual review flag | DEV-2 |
| Database growth | Implement data archival strategy | DEV-1 |
| Interface mismatches | Daily interface sync, typed contracts | ALL |
| Integration failures | Early integration checkpoint on Day 4 | ALL |

---

## Next Steps After Prototype

1. **Production Database**: Migrate SQLite â†’ PostgreSQL
2. **API Layer**: Add REST API for backend integration
3. **AI Agent Endpoints**: Create query endpoints for agents
4. **Scheduled Processing**: Add background job scheduler
5. **User Authentication**: Add login if multi-user needed
